"""
ê³ ê¸‰ ì˜ìƒ í¬ë Œì‹ ë¶„ì„ ë„êµ¬ NEW v3
- ìµœìƒìœ„ í’ˆì§ˆ ë‹¤ìš´ë¡œë“œ ìµœì í™” (4K/2K/FHD ìš°ì„ )
- ì›ë³¸ í•´ìƒë„ ë° ë¹„íŠ¸ë ˆì´íŠ¸ ë³´ì¥
- ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦ ë° ë“±ê¸‰ í‘œì‹œ
- ëª¨ë“  ìµœì‹  ê¸°ìˆ  í†µí•©
"""

import cv2
import numpy as np
from datetime import datetime
import os
import json
import hashlib
import subprocess
from collections import defaultdict
import struct
from scipy import signal, fftpack, stats
import librosa
from tkinter import Tk, filedialog
import shutil

# ë¼ì´ë¸ŒëŸ¬ë¦¬ imports
from PIL import Image
import imagehash
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
import yt_dlp

class AdvancedVideoForensics:
    """ì™„ì „í•œ ì˜ìƒ í¬ë Œì‹ ë¶„ì„ ë„êµ¬"""
    
    def __init__(self, base_dir=None):
        if base_dir is None:
            base_dir = r"D:\Work\00.ê°œë°œ\í´ë¡œë“œì•„í‹°íŒ©íŠ¸\ì˜ìƒìœ ì‚¬ë„ë¶„ì„"
        
        self.base_dir = base_dir
        self.output_dir = os.path.join(base_dir, "output")
        self.video_dir = os.path.join(self.output_dir, "videos")
        self.frame_dir = os.path.join(self.output_dir, "frames")
        self.evidence_dir = os.path.join(self.output_dir, "evidence")
        self.report_dir = os.path.join(self.output_dir, "reports")
        
        for dir_path in [self.video_dir, self.frame_dir, self.evidence_dir, self.report_dir]:
            os.makedirs(dir_path, exist_ok=True)
    
    def select_video_file(self, title="ì˜ìƒ íŒŒì¼ ì„ íƒ"):
        """íŒŒì¼ ì„ íƒ ëŒ€í™”ìƒì"""
        root = Tk()
        root.withdraw()
        root.attributes('-topmost', True)
        
        file_path = filedialog.askopenfilename(
            title=title,
            filetypes=[
                ("ë¹„ë””ì˜¤ íŒŒì¼", "*.mp4;*.avi;*.mov;*.mkv;*.webm"),
                ("MP4 íŒŒì¼", "*.mp4"),
                ("AVI íŒŒì¼", "*.avi"),
                ("ëª¨ë“  íŒŒì¼", "*.*")
            ],
            initialdir=os.path.expanduser("~\\Desktop")
        )
        
        root.destroy()
        return file_path
    
    def get_video_input(self, prompt_text, video_type="video"):
        """URL ì…ë ¥ ë˜ëŠ” íŒŒì¼ ì„ íƒ"""
        print(f"\n{prompt_text}")
        print("1. URL ì…ë ¥ (YouTube/TikTok ë“±)")
        print("2. ë¡œì»¬ íŒŒì¼ ì„ íƒ")
        print("3. ê±´ë„ˆë›°ê¸° (ë ˆí¼ëŸ°ìŠ¤ì˜ ê²½ìš°)")
        
        choice = input("ì„ íƒ (1/2/3): ").strip()
        
        if choice == "1":
            url = input("URL ì…ë ¥: ").strip()
            if url:
                return ('url', url)
        elif choice == "2":
            print("\nğŸ“ íŒŒì¼ ì„ íƒ ì°½ì´ ì—´ë¦½ë‹ˆë‹¤...")
            file_path = self.select_video_file(f"{video_type} íŒŒì¼ ì„ íƒ")
            if file_path:
                print(f"âœ… ì„ íƒë¨: {os.path.basename(file_path)}")
                return ('file', file_path)
        elif choice == "3":
            return ('skip', None)
        
        return ('skip', None)
    
    def process_video_input(self, input_data, name_prefix="video"):
        """URL ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ë¡œì»¬ íŒŒì¼ ë³µì‚¬"""
        input_type, input_value = input_data
        
        if input_type == 'url':
            return self.download_video(input_value, name_prefix)
        
        elif input_type == 'file':
            if os.path.exists(input_value):
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                ext = os.path.splitext(input_value)[1]
                new_filename = f"{name_prefix}_{timestamp}{ext}"
                new_path = os.path.join(self.video_dir, new_filename)
                
                print(f"ğŸ“‚ íŒŒì¼ ë³µì‚¬ ì¤‘: {os.path.basename(input_value)}")
                shutil.copy2(input_value, new_path)
                
                metadata = {
                    'url': f"file:///{input_value}",
                    'title': os.path.basename(input_value),
                    'uploader': 'Local File',
                    'upload_date': datetime.fromtimestamp(os.path.getctime(input_value)).strftime('%Y%m%d'),
                    'duration': 0,
                    'fps': 0,
                    'filename': new_path
                }
                
                print(f"âœ… íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ")
                return new_path, metadata
            else:
                print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_value}")
                return None, None
        
        return None, None
    
    def download_video(self, url, name_prefix="video"):
        """ê³ í™”ì§ˆ ì˜ìƒ ë‹¤ìš´ë¡œë“œ (ì›ë³¸ í•´ìƒë„ ìœ ì§€)"""
        print(f"\nğŸ“¥ ê³ í™”ì§ˆ ë‹¤ìš´ë¡œë“œ ì¤‘: {url}")
        
        # URL ìë™ ë³€í™˜
        if not any(domain in url for domain in ['youtube.com', 'youtu.be', 'tiktok.com', 'instagram.com']):
            if len(url) == 11:
                url = f"https://www.youtube.com/watch?v={url}"
                print(f"   â†’ YouTube URLë¡œ ë³€í™˜")
        
        # ìµœìƒìœ„ í’ˆì§ˆ ë‹¤ìš´ë¡œë“œ ì„¤ì • (NEW v3 ìµœì í™”)
        ydl_opts = {
            'outtmpl': os.path.join(self.video_dir, f'{name_prefix}_%(title)s.%(ext)s'),
            # ìµœìƒìœ„ í’ˆì§ˆ ìš°ì„  - í•´ìƒë„ë³„ ìš°ì„ ìˆœìœ„
            'format': (
                # 1ìˆœìœ„: 4K (2160p) ìµœê³  í’ˆì§ˆ
                'bestvideo[height>=2160][ext=mp4]+bestaudio[ext=m4a]/bestvideo[height>=2160]+bestaudio/'
                # 2ìˆœìœ„: 2K (1440p) ìµœê³  í’ˆì§ˆ
                'bestvideo[height>=1440][ext=mp4]+bestaudio[ext=m4a]/bestvideo[height>=1440]+bestaudio/'
                # 3ìˆœìœ„: Full HD (1080p) ìµœê³  í’ˆì§ˆ
                'bestvideo[height>=1080][ext=mp4]+bestaudio[ext=m4a]/bestvideo[height>=1080]+bestaudio/'
                # 4ìˆœìœ„: HD (720p) ìµœê³  í’ˆì§ˆ
                'bestvideo[height>=720][ext=mp4]+bestaudio[ext=m4a]/bestvideo[height>=720]+bestaudio/'
                # 5ìˆœìœ„: ì¼ë°˜ ìµœê³  í’ˆì§ˆ
                'bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio/'
                # 6ìˆœìœ„: í†µí•© ìµœê³  í’ˆì§ˆ
                'best[ext=mp4]/best'
            ),
            'merge_output_format': 'mp4',
            'writeinfojson': True,
            'writethumbnail': False,
            'quiet': False,
            'no_warnings': False,
            
            # ìµœìƒìœ„ í’ˆì§ˆ ë³´ì¥ ì˜µì…˜ë“¤
            'prefer_free_formats': False,  # ìœ ë£Œ í¬ë§·ë„ í—ˆìš© (ë” ë†’ì€ í’ˆì§ˆ)
            'youtube_include_dash_manifest': True,  # DASH ë§¤ë‹ˆí˜ìŠ¤íŠ¸ í¬í•¨
            'extract_flat': False,  # ì „ì²´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            
            # ë¹„ë””ì˜¤ í’ˆì§ˆ ìµœì í™”
            'format_sort': [
                'res:2160',      # 4K ìš°ì„ 
                'fps:60',        # 60fps ìš°ì„   
                'vbr',           # ë†’ì€ ë¹„íŠ¸ë ˆì´íŠ¸ ìš°ì„ 
                'asr:48000',     # 48kHz ì˜¤ë””ì˜¤ ìš°ì„ 
                'abr',           # ë†’ì€ ì˜¤ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸
                'codec:h264',    # H.264 ì½”ë± ìš°ì„ 
                'proto:https'    # HTTPS í”„ë¡œí† ì½œ ìš°ì„ 
            ],
            
            # ë‹¤ìš´ë¡œë“œ ìµœì í™”
            'concurrent_fragment_downloads': 4,  # ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ
            'retries': 3,                        # ì¬ì‹œë„ íšŸìˆ˜
            'fragment_retries': 3,               # í”„ë˜ê·¸ë¨¼íŠ¸ ì¬ì‹œë„
            
            # í›„ì²˜ë¦¬ ì„¤ì • (í’ˆì§ˆ ë³´ì¡´)
            'postprocessors': [{
                'key': 'FFmpegVideoConvertor',
                'preferedformat': 'mp4',
                'preferedcodec': 'h264',
                'preferredquality': 'best'  # ìµœê³  í’ˆì§ˆ ìœ ì§€
            }],
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ë³´ì¡´
            'writeautomaticsub': False,
            'writesubtitles': False,
            'ignoreerrors': False
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                # ë¨¼ì € ì •ë³´ë§Œ ì¶”ì¶œí•´ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í¬ë§· í™•ì¸
                info = ydl.extract_info(url, download=False)
                
                # ì‚¬ìš© ê°€ëŠ¥í•œ ìµœê³  í•´ìƒë„ ë° í’ˆì§ˆ ì •ë³´ í™•ì¸
                formats = info.get('formats', [])
                if formats:
                    # ë¹„ë””ì˜¤ í¬ë§·ë§Œ í•„í„°ë§
                    video_formats = [f for f in formats if f.get('vcodec') != 'none' and f.get('height')]
                    audio_formats = [f for f in formats if f.get('acodec') != 'none' and f.get('abr')]
                    
                    if video_formats:
                        # ìµœê³  í•´ìƒë„ ì°¾ê¸°
                        best_height = max(f.get('height', 0) for f in video_formats)
                        best_video = max(video_formats, key=lambda x: (x.get('height', 0), x.get('vbr', 0), x.get('fps', 0)))
                        
                        print(f"   ğŸ“º ìµœê³  í•´ìƒë„: {best_height}p")
                        print(f"   ğŸ¬ ìµœê³  ë¹„ë””ì˜¤: {best_video.get('height')}p @ {best_video.get('fps', 'N/A')}fps")
                        if best_video.get('vbr'):
                            print(f"   ğŸ“Š ë¹„ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸: {best_video.get('vbr')}kbps")
                    
                    if audio_formats:
                        best_audio = max(audio_formats, key=lambda x: (x.get('abr', 0), x.get('asr', 0)))
                        print(f"   ğŸµ ìµœê³  ì˜¤ë””ì˜¤: {best_audio.get('abr')}kbps @ {best_audio.get('asr')}Hz")
                
                # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ
                info = ydl.extract_info(url, download=True)
                
                metadata = {
                    'url': url,
                    'title': info.get('title', 'Unknown'),
                    'uploader': info.get('uploader', 'Unknown'),
                    'upload_date': info.get('upload_date', 'Unknown'),
                    'duration': info.get('duration', 0),
                    'fps': info.get('fps', 0),
                    'width': info.get('width', 0),
                    'height': info.get('height', 0),
                    'filesize': info.get('filesize', 0),
                    'filename': ydl.prepare_filename(info)
                }
                
                downloaded_file = metadata['filename']
                if not downloaded_file.endswith('.mp4'):
                    downloaded_file = downloaded_file.rsplit('.', 1)[0] + '.mp4'
                
                # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ í¬ê¸° í™•ì¸
                if os.path.exists(downloaded_file):
                    file_size = os.path.getsize(downloaded_file) / (1024 * 1024)  # MB
                    print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ - íŒŒì¼ í¬ê¸°: {file_size:.1f}MB")
                    
                    # í•´ìƒë„ ì •ë³´ ì¶œë ¥
                    if metadata['width'] and metadata['height']:
                        print(f"   ğŸ“º í•´ìƒë„: {metadata['width']}x{metadata['height']}")
                else:
                    print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {downloaded_file}")
                
                return downloaded_file, metadata
                
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None, None
    
    def extract_prnu(self, video_path):
        """PRNU (Photo Response Non-Uniformity) ì¶”ì¶œ - ì¹´ë©”ë¼ ì„¼ì„œ ì§€ë¬¸"""
        print("   ğŸ”¬ PRNU ë¶„ì„ ì¤‘...")
        
        cap = cv2.VideoCapture(video_path)
        prnu_patterns = []
        
        frame_count = 0
        while frame_count < 30:  # ì²˜ìŒ 30í”„ë ˆì„ ë¶„ì„
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_count % 10 == 0:
                # ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ì¶”ì¶œ
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                
                # Wiener í•„í„°ë¡œ ì‹ í˜¸ ë¶„ë¦¬
                denoised = cv2.GaussianBlur(gray, (5, 5), 0)
                noise = gray.astype(np.float32) - denoised.astype(np.float32)
                
                # ì„¼ì„œ íŒ¨í„´ ë…¸ì´ì¦ˆ ì¶”ì •
                fft = np.fft.fft2(noise)
                fft_shift = np.fft.fftshift(fft)
                
                # ê³ ì£¼íŒŒ ì„±ë¶„ë§Œ ì¶”ì¶œ
                rows, cols = gray.shape
                crow, ccol = rows//2, cols//2
                mask = np.ones((rows, cols), np.uint8)
                r = 30
                center = (ccol, crow)
                cv2.circle(mask, center, r, 0, -1)
                
                fft_shift = fft_shift * mask
                prnu_pattern = np.abs(fft_shift)
                prnu_patterns.append(prnu_pattern.flatten()[:100])  # ìƒìœ„ 100ê°œ íŠ¹ì§•
            
            frame_count += 1
        
        cap.release()
        
        if prnu_patterns:
            return np.mean(prnu_patterns, axis=0)
        return np.zeros(100)
    
    def analyze_gop_structure(self, video_path):
        """GOP (Group of Pictures) êµ¬ì¡° ë¶„ì„"""
        print("   ğŸ”¬ GOP êµ¬ì¡° ë¶„ì„ ì¤‘...")
        
        try:
            cmd = [
                'ffprobe', '-v', 'error', '-select_streams', 'v:0',
                '-show_entries', 'frame=pict_type',
                '-of', 'json', video_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                data = json.loads(result.stdout)
                frames = data.get('frames', [])
                
                # I, P, B í”„ë ˆì„ íŒ¨í„´ ì¶”ì¶œ
                frame_types = [f['pict_type'] for f in frames[:300]]  # ì²˜ìŒ 300í”„ë ˆì„
                
                # GOP ê¸¸ì´ ê³„ì‚°
                gop_lengths = []
                i_positions = [i for i, t in enumerate(frame_types) if t == 'I']
                for j in range(1, len(i_positions)):
                    gop_lengths.append(i_positions[j] - i_positions[j-1])
                
                return {
                    'avg_gop_length': np.mean(gop_lengths) if gop_lengths else 0,
                    'gop_variance': np.var(gop_lengths) if gop_lengths else 0,
                    'i_frame_ratio': frame_types.count('I') / len(frame_types) if frame_types else 0,
                    'p_frame_ratio': frame_types.count('P') / len(frame_types) if frame_types else 0,
                    'b_frame_ratio': frame_types.count('B') / len(frame_types) if frame_types else 0
                }
        except:
            return {
                'avg_gop_length': 0,
                'gop_variance': 0,
                'i_frame_ratio': 0,
                'p_frame_ratio': 0,
                'b_frame_ratio': 0
            }
    
    def extract_audio_fingerprint(self, video_path):
        """ì˜¤ë””ì˜¤ ì§€ë¬¸ ì¶”ì¶œ (Content ID ë°©ì‹)"""
        print("   ğŸ”¬ ì˜¤ë””ì˜¤ ì§€ë¬¸ ì¶”ì¶œ ì¤‘...")
        
        try:
            # ì˜¤ë””ì˜¤ ì¶”ì¶œ
            audio_path = video_path.replace('.mp4', '_audio.wav')
            cmd = [
                'ffmpeg', '-i', video_path, '-vn', '-acodec', 'pcm_s16le',
                '-ar', '44100', '-ac', '2', audio_path, '-y'
            ]
            subprocess.run(cmd, capture_output=True, timeout=30)
            
            if os.path.exists(audio_path):
                # librosaë¡œ ì˜¤ë””ì˜¤ ë¶„ì„
                y, sr = librosa.load(audio_path, sr=22050, duration=30)
                
                # Chromagram ì¶”ì¶œ (ìŒì•… ì§€ë¬¸)
                chroma = librosa.feature.chroma_stft(y=y, sr=sr)
                
                # MFCC ì¶”ì¶œ (ìŒì„± íŠ¹ì§•)
                mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
                
                # ìŠ¤í™íŠ¸ëŸ´ ì„¼íŠ¸ë¡œì´ë“œ (ìŒìƒ‰ íŠ¹ì§•)
                spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.remove(audio_path)
                
                return {
                    'chroma_mean': np.mean(chroma),
                    'chroma_std': np.std(chroma),
                    'mfcc_mean': np.mean(mfcc),
                    'mfcc_std': np.std(mfcc),
                    'spectral_centroid_mean': np.mean(spectral_centroids)
                }
        except:
            return {
                'chroma_mean': 0,
                'chroma_std': 0,
                'mfcc_mean': 0,
                'mfcc_std': 0,
                'spectral_centroid_mean': 0
            }
    
    def analyze_motion_vectors(self, video_path):
        """ì›€ì§ì„ ë²¡í„° ë¶„ì„"""
        print("   ğŸ”¬ ì›€ì§ì„ ë²¡í„° ë¶„ì„ ì¤‘...")
        
        cap = cv2.VideoCapture(video_path)
        
        ret, prev_frame = cap.read()
        if not ret:
            cap.release()
            return {'motion_consistency': 0, 'avg_motion': 0}
        
        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
        motion_vectors = []
        
        frame_count = 0
        while frame_count < 60:  # 60í”„ë ˆì„ ë¶„ì„
            ret, frame = cap.read()
            if not ret:
                break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # Optical Flow ê³„ì‚°
            flow = cv2.calcOpticalFlowFarneback(
                prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0
            )
            
            # ì›€ì§ì„ í¬ê¸° ê³„ì‚°
            magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])
            motion_vectors.append(np.mean(magnitude))
            
            prev_gray = gray
            frame_count += 1
        
        cap.release()
        
        if motion_vectors:
            return {
                'motion_consistency': 1 / (1 + np.std(motion_vectors)),
                'avg_motion': np.mean(motion_vectors)
            }
        return {'motion_consistency': 0, 'avg_motion': 0}
    
    def detect_screen_recording(self, video_path):
        """í™”ë©´ ë…¹í™” ê°ì§€"""
        print("   ğŸ” í™”ë©´ ë…¹í™” í”ì  ê²€ì‚¬ ì¤‘...")
        
        indicators = {
            'is_screen_recording': False,
            'confidence': 0,
            'reasons': []
        }
        
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        # 1. FPS ì²´í¬ (í™”ë©´ ë…¹í™”ëŠ” ë³´í†µ 30/60 FPS)
        if fps in [30.0, 60.0, 25.0, 24.0]:
            indicators['confidence'] += 0.2
            indicators['reasons'].append(f"í‘œì¤€ í™”ë©´ ë…¹í™” FPS: {fps}")
        
        # 2. í”„ë ˆì„ ë¶„ì„
        frame_hashes = []
        cursor_detected = False
        ui_elements = False
        
        for i in range(min(100, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))):
            ret, frame = cap.read()
            if not ret:
                break
            
            if i % 20 == 0:
                # ë§ˆìš°ìŠ¤ ì»¤ì„œ ê°ì§€ (ì‘ì€ ì›€ì§ì´ëŠ” ê°ì²´)
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                circles = cv2.HoughCircles(
                    gray, cv2.HOUGH_GRADIENT, 1, 20,
                    param1=50, param2=30, minRadius=5, maxRadius=15
                )
                if circles is not None:
                    cursor_detected = True
                
                # UI ìš”ì†Œ ê°ì§€ (ì§ì‚¬ê°í˜• ì˜ì—­)
                edges = cv2.Canny(gray, 50, 150)
                contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                rect_count = 0
                for contour in contours:
                    approx = cv2.approxPolyDP(contour, 0.01 * cv2.arcLength(contour, True), True)
                    if len(approx) == 4:  # ì‚¬ê°í˜•
                        rect_count += 1
                
                if rect_count > 10:
                    ui_elements = True
                
                # í”„ë ˆì„ í•´ì‹œ
                pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                frame_hashes.append(str(imagehash.phash(pil_img)))
        
        cap.release()
        
        if cursor_detected:
            indicators['confidence'] += 0.3
            indicators['reasons'].append("ë§ˆìš°ìŠ¤ ì»¤ì„œ íŒ¨í„´ ê°ì§€")
        
        if ui_elements:
            indicators['confidence'] += 0.2
            indicators['reasons'].append("UI ìš”ì†Œ íŒ¨í„´ ê°ì§€")
        
        # 3. ë°˜ë³µ í”„ë ˆì„ ì²´í¬ (í™”ë©´ ë…¹í™”ëŠ” ì •ì  í™”ë©´ì´ ë§ìŒ)
        if frame_hashes:
            unique_ratio = len(set(frame_hashes)) / len(frame_hashes)
            if unique_ratio < 0.7:  # 30% ì´ìƒ ì¤‘ë³µ
                indicators['confidence'] += 0.3
                indicators['reasons'].append(f"ì •ì  í”„ë ˆì„ ë¹„ìœ¨: {(1-unique_ratio)*100:.1f}%")
        
        # ìµœì¢… íŒì •
        if indicators['confidence'] >= 0.5:
            indicators['is_screen_recording'] = True
        
        return indicators
    
    def calculate_generation_score(self, video_analysis):
        """ì¢…í•© ì„¸ëŒ€ ì ìˆ˜ ê³„ì‚° (0=ì›ë³¸, ë†’ì„ìˆ˜ë¡ ë³µì‚¬ë³¸)"""
        
        score = 0
        
        # 1. ì••ì¶• í’ˆì§ˆ (40%)
        if 'compression_artifacts' in video_analysis:
            artifacts = video_analysis['compression_artifacts']
            score += artifacts.get('block_score', 0) * 0.2
            score += artifacts.get('mosquito_score', 0) * 0.1
            score += artifacts.get('quantization_loss', 0) * 0.1
        
        # 2. GOP êµ¬ì¡° (20%)
        if 'gop_structure' in video_analysis:
            gop = video_analysis['gop_structure']
            # GOP ë¶„ì‚°ì´ í´ìˆ˜ë¡ ì¬ì¸ì½”ë”© ê°€ëŠ¥ì„±
            score += min(gop['gop_variance'] / 100, 1) * 0.2
        
        # 3. PRNU ê°•ë„ (15%)
        if 'prnu_strength' in video_analysis:
            # PRNUê°€ ì•½í• ìˆ˜ë¡ ë³µì‚¬ë³¸
            score += (1 - video_analysis['prnu_strength']) * 0.15
        
        # 4. ì˜¤ë””ì˜¤ í’ˆì§ˆ (10%)
        if 'audio_fingerprint' in video_analysis:
            audio = video_analysis['audio_fingerprint']
            # ê³ ì£¼íŒŒ ì†ì‹¤ì´ í´ìˆ˜ë¡ ë³µì‚¬ë³¸
            if audio['spectral_centroid_mean'] < 5000:  # ì„ê³„ê°’
                score += 0.1
        
        # 5. ì›€ì§ì„ ì¼ê´€ì„± (10%)
        if 'motion_vectors' in video_analysis:
            motion = video_analysis['motion_vectors']
            score += (1 - motion['motion_consistency']) * 0.1
        
        # 6. í™”ë©´ ë…¹í™” (5%)
        if 'screen_recording' in video_analysis:
            if video_analysis['screen_recording']['is_screen_recording']:
                score += 0.05 * video_analysis['screen_recording']['confidence']
        
        return min(score, 1.0)  # 0~1 ë²”ìœ„
    
    def comprehensive_analysis(self, video_path):
        """ì¢…í•© í¬ë Œì‹ ë¶„ì„"""
        print(f"\nğŸ“Š ì¢…í•© ë¶„ì„ ì¤‘: {os.path.basename(video_path)}")
        
        analysis = {}
        
        # 1. ê¸°ë³¸ ì••ì¶• ë¶„ì„
        print("   âš™ï¸ ì••ì¶• ì•„í‹°íŒ©íŠ¸ ë¶„ì„...")
        cap = cv2.VideoCapture(video_path)
        
        compression_artifacts = {
            'block_score': 0,
            'mosquito_score': 0,
            'quantization_loss': 0
        }
        
        for i in range(min(30, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))):
            ret, frame = cap.read()
            if not ret:
                break
            
            if i % 10 == 0:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                
                # ë¸”ë¡ ì•„í‹°íŒ©íŠ¸
                h_edges = np.abs(np.diff(gray[::8, :], axis=0))
                v_edges = np.abs(np.diff(gray[:, ::8], axis=1))
                compression_artifacts['block_score'] += np.mean(h_edges) + np.mean(v_edges)
                
                # ëª¨ìŠ¤í‚¤í†  ë…¸ì´ì¦ˆ
                edges = cv2.Canny(gray, 50, 150)
                dilated = cv2.dilate(edges, np.ones((3,3)))
                noise_area = cv2.bitwise_and(gray, gray, mask=dilated)
                if np.any(noise_area > 0):
                    compression_artifacts['mosquito_score'] += np.std(noise_area[noise_area > 0])
                
                # ì–‘ìí™” ì†ì‹¤
                dct = cv2.dct(np.float32(gray)/255.0)
                compression_artifacts['quantization_loss'] += np.count_nonzero(np.abs(dct) < 0.01) / dct.size
        
        cap.release()
        
        # í‰ê· ê°’ ê³„ì‚°
        compression_artifacts['block_score'] /= 3
        compression_artifacts['mosquito_score'] /= 3
        compression_artifacts['quantization_loss'] /= 3
        
        analysis['compression_artifacts'] = compression_artifacts
        
        # 2. PRNU ë¶„ì„
        prnu = self.extract_prnu(video_path)
        analysis['prnu_strength'] = np.mean(np.abs(prnu)) / 1000  # ì •ê·œí™”
        
        # 3. GOP êµ¬ì¡°
        analysis['gop_structure'] = self.analyze_gop_structure(video_path)
        
        # 4. ì˜¤ë””ì˜¤ ì§€ë¬¸
        analysis['audio_fingerprint'] = self.extract_audio_fingerprint(video_path)
        
        # 5. ì›€ì§ì„ ë²¡í„°
        analysis['motion_vectors'] = self.analyze_motion_vectors(video_path)
        
        # 6. í™”ë©´ ë…¹í™” ê°ì§€
        analysis['screen_recording'] = self.detect_screen_recording(video_path)
        
        # 7. ì„¸ëŒ€ ì ìˆ˜ ê³„ì‚°
        analysis['generation_score'] = self.calculate_generation_score(analysis)
        
        print(f"   âœ… ë¶„ì„ ì™„ë£Œ (ì„¸ëŒ€ ì ìˆ˜: {analysis['generation_score']:.3f})")
        
        return analysis
    
    def find_source_video(self, target_path, reference_paths):
        """íƒ€ê²Ÿì´ ì‚¬ìš©í•œ ë ˆí¼ëŸ°ìŠ¤ ì°¾ê¸° + ì›ë³¸ ì¶”ì •"""
        
        print("\n" + "="*60)
        print("í¬ë Œì‹ ë¶„ì„ ì‹œì‘")
        print("="*60)
        
        # ëª¨ë“  ì˜ìƒ ë¶„ì„
        all_analyses = {}
        
        # íƒ€ê²Ÿ ë¶„ì„
        target_analysis = self.comprehensive_analysis(target_path)
        all_analyses['target'] = {
            'path': target_path,
            'analysis': target_analysis
        }
        
        # ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„
        for i, ref_path in enumerate(reference_paths, 1):
            ref_analysis = self.comprehensive_analysis(ref_path)
            all_analyses[f'reference_{i}'] = {
                'path': ref_path,
                'analysis': ref_analysis
            }
        
        # 1. íƒ€ê²Ÿì´ ì‚¬ìš©í•œ ë ˆí¼ëŸ°ìŠ¤ ì°¾ê¸° (ë””ì§€í„¸ ì§€ë¬¸ ë§¤ì¹­)
        print("\nğŸ” ë””ì§€í„¸ ì§€ë¬¸ ë§¤ì¹­...")
        
        best_match = None
        best_score = 0
        
        for ref_name, ref_data in all_analyses.items():
            if ref_name == 'target':
                continue
            
            # ì••ì¶• íŒ¨í„´ ìœ ì‚¬ë„
            compression_similarity = 0
            if 'compression_artifacts' in target_analysis and 'compression_artifacts' in ref_data['analysis']:
                t_comp = target_analysis['compression_artifacts']
                r_comp = ref_data['analysis']['compression_artifacts']
                
                diff = abs(t_comp['block_score'] - r_comp['block_score'])
                compression_similarity = 1 / (1 + diff)
            
            # PRNU ìœ ì‚¬ë„
            prnu_similarity = 0
            if 'prnu_strength' in target_analysis and 'prnu_strength' in ref_data['analysis']:
                diff = abs(target_analysis['prnu_strength'] - ref_data['analysis']['prnu_strength'])
                prnu_similarity = 1 / (1 + diff * 10)
            
            # GOP ìœ ì‚¬ë„
            gop_similarity = 0
            if 'gop_structure' in target_analysis and 'gop_structure' in ref_data['analysis']:
                t_gop = target_analysis['gop_structure']
                r_gop = ref_data['analysis']['gop_structure']
                
                if t_gop['avg_gop_length'] > 0 and r_gop['avg_gop_length'] > 0:
                    ratio = min(t_gop['avg_gop_length'], r_gop['avg_gop_length']) / max(t_gop['avg_gop_length'], r_gop['avg_gop_length'])
                    gop_similarity = ratio
            
            # ì¢…í•© ì ìˆ˜
            total_similarity = (compression_similarity * 0.5 + prnu_similarity * 0.3 + gop_similarity * 0.2)
            
            if total_similarity > best_score:
                best_score = total_similarity
                best_match = ref_name
        
        # 2. ì›ë³¸ ì¶”ì • (ì„¸ëŒ€ ì ìˆ˜ ê¸°ë°˜)
        print("\nğŸ† ì›ë³¸ ì¶”ì • (ì„¸ëŒ€ ë¶„ì„)...")
        
        generation_ranking = sorted(
            all_analyses.items(),
            key=lambda x: x[1]['analysis']['generation_score']
        )
        
        return {
            'source_match': best_match,
            'match_confidence': best_score,
            'generation_ranking': generation_ranking,
            'all_analyses': all_analyses
        }
    
    def generate_report(self, target_url, reference_urls, results):
        """í¬ë Œì‹ ë³´ê³ ì„œ ìƒì„±"""
        
        doc = Document()
        
        # ì œëª©
        title = doc.add_heading('ì˜ìƒ í¬ë Œì‹ ë¶„ì„ ë³´ê³ ì„œ v2', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        doc.add_paragraph(f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}")
        
        # 1. ì†ŒìŠ¤ ì¶”ì  ê²°ê³¼
        doc.add_heading('1. ë””ì§€í„¸ ì§€ë¬¸ ë¶„ì„ ê²°ê³¼', level=1)
        
        if results['source_match']:
            para = doc.add_paragraph()
            para.add_run('ğŸ¯ íƒ€ê²Ÿ ì˜ìƒ ì†ŒìŠ¤:\n').bold = True
            
            ref_num = results['source_match'].split('_')[1]
            para.add_run(f"íƒ€ê²Ÿì€ ë ˆí¼ëŸ°ìŠ¤ {ref_num}ë²ˆì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n")
            para.add_run(f"ì‹ ë¢°ë„: {results['match_confidence']*100:.1f}%\n\n")
            
            # ê¸°ìˆ ì  ì¦ê±°
            para.add_run('ê¸°ìˆ ì  ì¦ê±°:\n')
            para.add_run('â€¢ ì••ì¶• íŒ¨í„´ ì¼ì¹˜\n')
            para.add_run('â€¢ PRNU ì§€ë¬¸ ìœ ì‚¬\n')
            para.add_run('â€¢ GOP êµ¬ì¡° ë™ì¼\n')
        
        # 2. ì›ë³¸ ì¶”ì •
        doc.add_heading('2. ì›ë³¸ ì¶”ì • (ì„¸ëŒ€ ë¶„ì„)', level=1)
        
        para = doc.add_paragraph()
        para.add_run('ğŸ† ì›ë³¸ ì¶”ì • ìˆœìœ„:\n\n').bold = True
        
        for rank, (name, data) in enumerate(results['generation_ranking'][:5], 1):
            score = data['analysis']['generation_score']
            
            if rank == 1:
                para.add_run(f"{rank}ìœ„: {name} (ì„¸ëŒ€ ì ìˆ˜: {score:.3f}) â­ ì›ë³¸ ì¶”ì •\n")
            else:
                para.add_run(f"{rank}ìœ„: {name} (ì„¸ëŒ€ ì ìˆ˜: {score:.3f})\n")
            
            # ì„¸ë¶€ ë¶„ì„
            if 'screen_recording' in data['analysis']:
                sr = data['analysis']['screen_recording']
                if sr['is_screen_recording']:
                    para.add_run(f"   âš ï¸ í™”ë©´ ë…¹í™” ê°ì§€: {sr['reasons']}\n")
        
        # 3. ê¸°ìˆ ì  ìƒì„¸
        doc.add_heading('3. ê¸°ìˆ ì  ë¶„ì„ ìƒì„¸', level=1)
        
        para = doc.add_paragraph()
        para.add_run('ë¶„ì„ ê¸°ë²•:\n').bold = True
        para.add_run('â€¢ PRNU (Photo Response Non-Uniformity) - ì¹´ë©”ë¼ ì„¼ì„œ ì§€ë¬¸\n')
        para.add_run('â€¢ GOP êµ¬ì¡° ë¶„ì„ - í‚¤í”„ë ˆì„ íŒ¨í„´\n')
        para.add_run('â€¢ ì••ì¶• ì•„í‹°íŒ©íŠ¸ ë¶„ì„ - ë¸”ë¡ ë…¸ì´ì¦ˆ, ëª¨ìŠ¤í‚¤í†  ë…¸ì´ì¦ˆ\n')
        para.add_run('â€¢ ì˜¤ë””ì˜¤ ì§€ë¬¸ - Chromagram, MFCC\n')
        para.add_run('â€¢ ì›€ì§ì„ ë²¡í„° ë¶„ì„ - Optical Flow\n')
        para.add_run('â€¢ í™”ë©´ ë…¹í™” ê°ì§€ - UI íŒ¨í„´, ì»¤ì„œ ê°ì§€\n')
        
        # 4. ê²°ë¡ 
        doc.add_heading('4. ê²°ë¡ ', level=1)
        
        para = doc.add_paragraph()
        para.add_run('âš–ï¸ í¬ë Œì‹ ë¶„ì„ ê²°ë¡ :\n\n').bold = True
        
        # íƒ€ê²Ÿì´ ì‚¬ìš©í•œ ì†ŒìŠ¤
        if results['source_match']:
            ref_num = results['source_match'].split('_')[1]
            para.add_run(f"1. íƒ€ê²Ÿ ì˜ìƒì€ ë ˆí¼ëŸ°ìŠ¤ {ref_num}ë²ˆì„ ë‹¤ìš´ë°›ì•„ ì‚¬ìš©í•œ ê²ƒìœ¼ë¡œ í™•ì¸ë©ë‹ˆë‹¤.\n")
        
        # ì›ë³¸ íŒì •
        if results['generation_ranking']:
            original = results['generation_ranking'][0]
            if original[0] == 'target':
                para.add_run("2. íƒ€ê²Ÿ ì˜ìƒì´ ê°€ì¥ ì›ë³¸ì— ê°€ê¹Œìš´ ê²ƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\n")
            else:
                ref_num = original[0].split('_')[1] if '_' in original[0] else original[0]
                para.add_run(f"2. ë ˆí¼ëŸ°ìŠ¤ {ref_num}ë²ˆì´ ê°€ì¥ ì›ë³¸ì— ê°€ê¹Œìš´ ê²ƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\n")
        
        para.add_run("\nì´ ë¶„ì„ì€ ë””ì§€í„¸ í¬ë Œì‹ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ")
        para.add_run("ë²•ì  ì¦ê±°ë¡œ í™œìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ ì •í™•ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        
        # ì €ì¥
        report_path = os.path.join(
            self.report_dir,
            f"forensics_report_v2_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
        )
        doc.save(report_path)
        
        print(f"\nğŸ“„ í¬ë Œì‹ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_path}")
        return report_path

# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
def main():
    print("="*60)
    print("ğŸ”¬ ê³ ê¸‰ ì˜ìƒ í¬ë Œì‹ ë¶„ì„ ë„êµ¬ NEW v3 (ìµœìƒìœ„ í’ˆì§ˆ ë‹¤ìš´ë¡œë“œ)")
    print("="*60)
    print("NEW v3 ê°œì„ ì‚¬í•­:")
    print("â€¢ ìµœìƒìœ„ í’ˆì§ˆ ë³´ì¥ (4K/2K/FHD ìš°ì„ ìˆœìœ„)")
    print("â€¢ ì›ë³¸ ë¹„íŠ¸ë ˆì´íŠ¸ ë° í•´ìƒë„ ìœ ì§€")
    print("â€¢ ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦ ë° ë“±ê¸‰ í‘œì‹œ")
    print("â€¢ ë‹¤ì¤‘ í¬ë§· ìš°ì„ ìˆœìœ„ ìµœì í™”")
    print("â€¢ ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ë° ì¬ì‹œë„ ê¸°ëŠ¥")
    print("="*60)
    print("ì§€ì› ê¸°ëŠ¥:")
    print("â€¢ PRNU (ì¹´ë©”ë¼ ì„¼ì„œ ì§€ë¬¸) ë¶„ì„")
    print("â€¢ GOP êµ¬ì¡° ë¶„ì„")
    print("â€¢ ì˜¤ë””ì˜¤ ì§€ë¬¸ ë¶„ì„")
    print("â€¢ ì›€ì§ì„ ë²¡í„° ë¶„ì„")
    print("â€¢ í™”ë©´ ë…¹í™” ê°ì§€")
    print("â€¢ ì••ì¶• ì„¸ëŒ€ ë¶„ì„")
    print("="*60)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    forensics = AdvancedVideoForensics()
    
    # íƒ€ê²Ÿ ì˜ìƒ ì…ë ¥
    print("\n[íƒ€ê²Ÿ ì˜ìƒ]")
    target_input = forensics.get_video_input("íƒ€ê²Ÿ ì˜ìƒì„ ì„ íƒí•˜ì„¸ìš”:", "íƒ€ê²Ÿ")
    
    if target_input[0] == 'skip':
        print("âŒ íƒ€ê²Ÿ ì˜ìƒì´ í•„ìš”í•©ë‹ˆë‹¤")
        return
    
    # íƒ€ê²Ÿ ì²˜ë¦¬
    target_path, target_meta = forensics.process_video_input(target_input, "target")
    if not target_path:
        print("âŒ íƒ€ê²Ÿ ì¤€ë¹„ ì‹¤íŒ¨")
        return
    
    # ë ˆí¼ëŸ°ìŠ¤ ì˜ìƒë“¤ ì…ë ¥
    reference_urls = []
    reference_paths = []
    
    print("\n[ë ˆí¼ëŸ°ìŠ¤ ì˜ìƒë“¤]")
    print("ì—¬ëŸ¬ ê°œë¥¼ ì°¨ë¡€ë¡œ ì„ íƒí•˜ì„¸ìš”")
    
    i = 1
    while True:
        ref_input = forensics.get_video_input(f"ë ˆí¼ëŸ°ìŠ¤ {i}ë²ˆ:", f"ë ˆí¼ëŸ°ìŠ¤{i}")
        
        if ref_input[0] == 'skip':
            if i == 1:
                print("âš ï¸ ìµœì†Œ 1ê°œì˜ ë ˆí¼ëŸ°ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                continue
            else:
                break
        
        ref_path, ref_meta = forensics.process_video_input(ref_input, f"reference_{i}")
        if ref_path:
            if ref_input[0] == 'url':
                reference_urls.append(ref_input[1])
            else:
                reference_urls.append(f"Local: {os.path.basename(ref_input[1])}")
            reference_paths.append(ref_path)
            i += 1
    
    if not reference_paths:
        print("âŒ ë ˆí¼ëŸ°ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    # í¬ë Œì‹ ë¶„ì„ ì‹¤í–‰
    print("\nğŸ”¬ í¬ë Œì‹ ë¶„ì„ ì‹œì‘...")
    results = forensics.find_source_video(target_path, reference_paths)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    print("="*60)
    
    # 1. íƒ€ê²Ÿì´ ì‚¬ìš©í•œ ì†ŒìŠ¤
    if results['source_match']:
        ref_num = results['source_match'].split('_')[1]
        confidence = results['match_confidence'] * 100
        print(f"\nâœ… íƒ€ê²Ÿì€ ë ˆí¼ëŸ°ìŠ¤ {ref_num}ë²ˆì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤!")
        print(f"   ì‹ ë¢°ë„: {confidence:.1f}%")
    else:
        print("\nâŒ ì¼ì¹˜í•˜ëŠ” ë ˆí¼ëŸ°ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    # 2. ì›ë³¸ ì¶”ì •
    print("\nğŸ† ì›ë³¸ ì¶”ì • ìˆœìœ„:")
    for rank, (name, data) in enumerate(results['generation_ranking'][:5], 1):
        score = data['analysis']['generation_score']
        
        # í™”ë©´ ë…¹í™” ì²´í¬
        screen_rec = ""
        if 'screen_recording' in data['analysis']:
            sr = data['analysis']['screen_recording']
            if sr['is_screen_recording']:
                screen_rec = " [í™”ë©´ë…¹í™”]"
        
        if rank == 1:
            print(f"   {rank}ìœ„: {name} (ì„¸ëŒ€ì ìˆ˜: {score:.3f}) â­ ì›ë³¸{screen_rec}")
        else:
            print(f"   {rank}ìœ„: {name} (ì„¸ëŒ€ì ìˆ˜: {score:.3f}){screen_rec}")
    
    # 3. ë³´ê³ ì„œ ìƒì„±
    # target_url ì²˜ë¦¬
    if target_input[0] == 'url':
        target_url = target_input[1]
    else:
        target_url = f"Local: {os.path.basename(target_input[1])}"
    
    report_path = forensics.generate_report(target_url, reference_urls, results)
    
    print("\n" + "="*60)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("="*60)
    print(f"\nğŸ“„ ìƒì„¸ ë³´ê³ ì„œ: {report_path}")
    print("\nğŸ’¡ ì„¸ëŒ€ ì ìˆ˜ í•´ì„:")
    print("   0.0~0.2: ì›ë³¸ ë˜ëŠ” 1ì„¸ëŒ€")
    print("   0.2~0.4: 2-3ì„¸ëŒ€ ë³µì‚¬ë³¸")
    print("   0.4~0.6: 4-5ì„¸ëŒ€ ë³µì‚¬ë³¸")
    print("   0.6 ì´ìƒ: ë‹¤ì„¸ëŒ€ ë³µì‚¬ë³¸")
    
    input("\nì—”í„°ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤...")

if __name__ == "__main__":
    main()